#!/usr/bin/env python

import argparse
import numpy as np
import os.path
import shutil
import sys

from qir._qir import modis_qir
import qir._modis as modis

def writerestored(origpath, b6deaddets, verbose, savedir):
    dirname, filename = os.path.split(origpath)
    if savedir is not None:
        dirname = savedir
    restpath = os.path.join(dirname, "QIR."+filename)
    if os.path.exists(restpath):
        print >>sys.stderr, "%s already exists" % restpath
        return
    restored = modis_qir(origpath, b6deaddets=b6deaddets,
            verbose=verbose).astype('f8')

    shutil.copyfile(origpath, restpath)
    g = modis.Level1B(restpath, mode='w')
    try:
        b = g.radiance(6)
        b.write(restored)
        b.close()
    finally:
        g.close()
    if verbose > 0:
        print "QIR of %s saved at %s" % (origpath, restpath)

def get_parser():
    parser = argparse.ArgumentParser(formatter_class=argparse.RawDescriptionHelpFormatter,
description="""
Quantitatively restore band 6 of a MODIS granule.  The restored band 6 image
will be saved as a MODIS Level 1B HDF file with the same name as the granule
but with the prefix "QIR." added.""",
epilog="""For example, running the following will save the restored image at
/data/modis/QIR.MYD02HKM.A2010317.1935.005.2010318165656.hdf:

    qir /data/modis/MYD02HKM.A2010317.1935.005.2010318165656.hdf

Running the following will simulate dead detectors on the Terra granules and
save the restored images in the current working directory:

    qir -d 1,4,5,9,11,12,13,14,15,17,18,19 -s . \\
            /data/modis/MOD02HKM.*.hdf

The above can be processed must faster if done in parallel in a multi-core
machine:

    qir -d 1,4,5,9,11,12,13,14,15,17,18,19 -s . -p 8 \\
            /data/modis/MOD02HKM.*.hdf
""")
    parser.add_argument('granule', nargs='*',
        help="500m resolution MODIS granule filename.")
    parser.add_argument('-d', dest='detectors',
        help="""comma separated list of band 6 dead detectors
        that overrides the dead detectors specified in
        HDF attribute "Dead Detector List".
        The detectors are between 0 and 19 inclusively.""")
    parser.add_argument('-s', dest='dir',
        help="""directory where the result will be saved. The default
        is the same directory as the input granule.""")
    parser.add_argument('-p', dest='nproc', type=int, default=1,
        help="""process multiple granules in parallel using
        NPROC processes. It has no effect if we're processing
        only one granule. (default 1)""")
    parser.add_argument('--version', '-V', action='store_true',
        help="print version and exit.")
    parser.add_argument('--verbose', '-v', action='count',
        help="be verbose and print progress. Increases verbosity if given twice.")
    return parser

def main():
    parser = get_parser()
    args = parser.parse_args()

    if args.version:
        from qir import __version__
        print __version__
        sys.exit(2)
    if len(args.granule) == 0:
        parser.print_help()
        sys.exit(2)
    dets = None
    if args.detectors is not None:
        dets = np.array(sorted(set(int(d)
            for d in args.detectors.strip().split(','))), dtype='i')
        if np.any((dets < 0) | (19 < dets)):
            print >>sys.stderr, "invalid detector list:", args.detectors
            sys.exit(2)
    if args.dir is not None and not os.path.isdir(args.dir):
        os.makedirs(args.dir)

    if args.nproc > 1:
        from multiprocessing import Pool
        pool = Pool(args.nproc)
        for origpath in args.granule:
            pool.apply_async(writerestored,
                    [origpath, dets, args.verbose, args.dir])
        pool.close()
        pool.join()
    else:
        for origpath in args.granule:
            writerestored(origpath, dets, args.verbose, args.dir)

if __name__ == '__main__':
    main()
